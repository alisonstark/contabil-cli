# contabil-cli

Sistema de consolidaÃ§Ã£o e anÃ¡lise de demonstraÃ§Ãµes contÃ¡beis de operadoras de planos de saÃºde no Brasil.

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este projeto extrai, processa e consolida dados de demonstraÃ§Ãµes contÃ¡beis de operadoras de planos de saÃºde disponibilizados pela ANS (AgÃªncia Nacional de SaÃºde Suplementar), correlacionando-os com informaÃ§Ãµes cadastrais das operadoras.

O sistema baixa automaticamente os arquivos mais recentes (Ãºltimos 3 trimestres) do repositÃ³rio de dados abertos da ANS, processa as despesas, valida CNPJs, identifica inconsistÃªncias e gera relatÃ³rios consolidados prontos para anÃ¡lise.

## ğŸ¯ Funcionalidades

- âœ… Download automÃ¡tico de dados da ANS (FTP pÃºblico)
- âœ… Processamento de mÃºltiplos formatos (CSV, TXT, XLSX)
- âœ… ValidaÃ§Ã£o de CNPJs com algoritmo de mÃ³dulo 11
- âœ… DetecÃ§Ã£o de inconsistÃªncias (CNPJs duplicados, dados conflitantes)
- âœ… ConsolidaÃ§Ã£o de dados trimestrais
- âœ… Join estruturado com cadastro de operadoras
- âœ… GeraÃ§Ã£o de relatÃ³rios em formato brasileiro (sep=';', decimal=',')

## ğŸ“Š Arquivos Gerados

O sistema gera os seguintes arquivos na pasta `dados_consolidados/`:

1. **dados_processados_com_operadoras.csv** - Arquivo principal com todos os dados consolidados
2. **demonstracoes_contabeis_consolidadas.csv** - Dados consolidados antes do join com operadoras
3. **demonstracoes_contabeis_consolidadas_cnpjs_invalidos.csv** - CNPJs que falharam na validaÃ§Ã£o
4. **demonstracoes_contabeis_consolidadas_cnpjs_duplicados.csv** - CNPJs com mÃºltiplas razÃµes sociais
5. **demonstracoes_contabeis_consolidadas_operadoras_inconsistencias.csv** - Operadoras com dados conflitantes

## ğŸ—ï¸ Estrutura do Projeto

```
contabil-cli/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                    # Orquestrador principal do sistema
â”‚   â””â”€â”€ processamento_dados.py     # FunÃ§Ãµes de processamento e transformaÃ§Ã£o
â”œâ”€â”€ dados_consolidados/            # DiretÃ³rio de saÃ­da dos relatÃ³rios
â””â”€â”€ README.md                      # DocumentaÃ§Ã£o do projeto
```

## ğŸš€ Como Executar

```powershell
# Navegar atÃ© o diretÃ³rio do projeto
cd "c:\Users\moonpie\Documents\Git Projects\contabil-cli"

# Executar o script principal
python src/main.py
```

## ğŸ“š DecisÃµes de Arquitetura e ImplementaÃ§Ã£o

### 1. EstratÃ©gia de Processamento: In-Memory vs Incremental

**DecisÃ£o**: Processamento **incremental por trimestre**, mas **totalmente em memÃ³ria** dentro de cada trimestre.

**Justificativa**:
- Cada arquivo ZIP trimestral contÃ©m entre 1-5 arquivos (CSV/TXT/XLSX) com ~200-300MB descompactados
- Total estimado para 3 trimestres: **~600MB-1.5GB** de dados descompactados
- Processamento incremental **por trimestre** reduz pico de memÃ³ria
- Processamento **em memÃ³ria dentro de cada trimestre** mantÃ©m performance (sem I/O mÃºltiplo)
- Uso de `TemporaryDirectory`: arquivos sÃ£o **processados e descartados automaticamente**
- DataFrames do Pandas sÃ£o eficientes para esse volume (<2GB)

**ImplementaÃ§Ã£o**:
```python
# Loop processa um trimestre por vez
for arquivo in arquivos_trimestres:
    resultados = extrair_e_processar_zip(url_arquivo, df_operadoras)
    # Processa tudo em memÃ³ria, depois descarta
    dados_processados.extend(resultados)
```

### 2. ResiliÃªncia a VariaÃ§Ãµes de Estrutura

**Problema**: Diferentes trimestres e anos podem ter:
- Nomes de colunas diferentes (`REG_ANS` vs `REGISTRO_OPERADORA` vs `CD_REGISTRO_ANS`)
- Formatos de arquivo variados (CSV com `;`, TXT com `\t`, XLSX)
- Estruturas de diretÃ³rio inconsistentes

**DecisÃ£o**: **Busca dinÃ¢mica de colunas** + **Suporte multi-formato**.

**Justificativa**:
- Hardcoded column names quebram com mudanÃ§as na fonte de dados
- Cada formato tem caracterÃ­sticas especÃ­ficas (encoding, separadores)
- ValidaÃ§Ã£o antes de processar evita falhas silenciosas

**ImplementaÃ§Ã£o**:
```python
# Busca dinÃ¢mica por colunas
possiveis_nomes_despesas = ['REGISTRO_OPERADORA', 'REG_ANS', 'CD_REGISTRO_ANS', ...]
for nome in possiveis_nomes_despesas:
    if nome in df_despesas.columns:
        coluna_reg_ans_despesas = nome
        break

# Suporte multi-formato
if caminho_arquivo.endswith('.csv'):
    df = pd.read_csv(caminho_arquivo, encoding='latin1', sep=';')
elif caminho_arquivo.endswith('.txt'):
    df = pd.read_csv(caminho_arquivo, encoding='latin1', sep='\t')
elif caminho_arquivo.endswith('.xlsx'):
    df = pd.read_excel(caminho_arquivo)
```

**BenefÃ­cios**:
- âœ… Sistema continua funcionando mesmo com mudanÃ§as na nomenclatura da ANS
- âœ… Suporta qualquer formato encontrado nos arquivos ZIP
- âœ… Mensagens de debug mostram colunas disponÃ­veis quando algo falha

### 3. Tratamento de InconsistÃªncias

#### 3.1 CNPJs InvÃ¡lidos

**DecisÃ£o**: **Validar todos os CNPJs** com algoritmo de mÃ³dulo 11 e **segregar invÃ¡lidos** em arquivo separado.

**Justificativa**:
- CNPJs invÃ¡lidos indicam problemas na qualidade dos dados da fonte
- Manter invÃ¡lidos no arquivo principal polui anÃ¡lises
- Arquivo separado permite auditoria e correÃ§Ã£o manual

**ImplementaÃ§Ã£o**:
```python
def validar_cnpj(cnpj: str) -> bool:
    # Remove caracteres nÃ£o numÃ©ricos
    cnpj_numeros = re.sub(r'\D', '', str(cnpj))
    
    # Verifica 14 dÃ­gitos
    if len(cnpj_numeros) != 14:
        return False
    
    # Calcula dÃ­gitos verificadores (mÃ³dulo 11)
    # ... algoritmo completo no cÃ³digo
```

**Resultados**:
- ğŸ“„ `cnpjs_invalidos.csv`: CNPJs que falharam na validaÃ§Ã£o
- Inclui: CNPJ, REG_ANS, RazaoSocial para rastreabilidade
- Arquivo principal contÃ©m **apenas CNPJs vÃ¡lidos**

#### 3.2 CNPJs Duplicados com RazÃµes Sociais Diferentes

**Problema**: Mesmo CNPJ pode aparecer com nomes diferentes (erro de cadastro, mudanÃ§a de razÃ£o social, etc).

**DecisÃ£o**: **Detectar e reportar**, mas **manter todos os registros** no consolidado.

**Justificativa**:
- NÃ£o podemos decidir automaticamente qual nome estÃ¡ correto
- Remover seria perda de informaÃ§Ã£o
- RelatÃ³rio separado permite investigaÃ§Ã£o manual

**ImplementaÃ§Ã£o**:
```python
# Agrupa por CNPJ e verifica se hÃ¡ razÃµes sociais Ãºnicas > 1
duplicados = df.groupby('CNPJ').filter(lambda x: x['RazaoSocial'].nunique() > 1)
```

**Resultados**:
- ğŸ“„ `cnpjs_duplicados.csv`: Pares de razÃµes sociais diferentes para o mesmo CNPJ

#### 3.3 Operadoras com Dados Inconsistentes

**Problema**: Cadastro de operadoras pode ter CNPJs duplicados com RegistroANS, Modalidade ou UF diferentes.
Em healthtech dados inconsistentes viram erro regulatÃ³rio. SÃ©ria atenÃ§Ã£o aqui.

**DecisÃ£o**: **Detectar inconsistÃªncias** antes do join e **usar apenas o primeiro registro** (keep='first').

**Justificativa**:
- Join com duplicatas multiplica linhas (inflaÃ§Ã£o de dados)
- Usar `keep='first'` Ã© determinÃ­stico e previsÃ­vel
- RelatÃ³rio de inconsistÃªncias permite correÃ§Ã£o na fonte

**ImplementaÃ§Ã£o**:
```python
# Detecta e salva inconsistÃªncias
salvar_operadoras_duplicadas_com_inconsistencias(df_operadoras, caminho)

# Remove duplicatas antes do join
df_operadoras_unicas = df_operadoras.drop_duplicates(subset=['CNPJ'], keep='first')
```

**Resultados**:
- ğŸ“„ `operadoras_inconsistencias.csv`: CNPJs com dados conflitantes no cadastro
- Colunas marcadas com `[INCONSISTENTE]` para fÃ¡cil identificaÃ§Ã£o

#### 3.4 Erros de PrecisÃ£o de Ponto Flutuante

**Problema**: Valores monetÃ¡rios podem ter erros como "759558,3999999994" devido Ã  precisÃ£o float.

**DecisÃ£o**: **Arredondar para 2 casas decimais** em todas as etapas.

**Justificativa**:
- Valores monetÃ¡rios no Brasil usam 2 casas decimais
- Arredondamento elimina artefatos de precisÃ£o flutuante
- Aplicado apÃ³s conversÃ£o e apÃ³s agregaÃ§Ãµes

**ImplementaÃ§Ã£o**:
```python
# Converte e arredonda
df_filtered[col] = pd.to_numeric(
    df_filtered[col].astype(str).str.replace(',', '.'),
    errors='coerce'
).round(2)

# Arredonda apÃ³s agregaÃ§Ã£o
df_consolidado['ValorDespesas'] = df_consolidado['ValorDespesas'].round(2)
```

### 4. EstratÃ©gia de Join

**Problema**: Correlacionar despesas (por REG_ANS) com operadoras (CNPJ + cadastro).

**DecisÃ£o**: **Join em duas etapas**:
1. **Inner join** Despesas Ã— Operadoras (por REG_ANS) â†’ adiciona CNPJ
2. **Left join** Consolidado Ã— Operadoras (por CNPJ) â†’ adiciona RegistroANS, Modalidade, UF

**Justificativa**:

**Primeira etapa (Inner Join)**:
- Garante que sÃ³ processamos despesas de operadoras conhecidas
- Adiciona CNPJ necessÃ¡rio para consolidaÃ§Ã£o
- Filtra dados Ã³rfÃ£os (sem operadora correspondente)

**Segunda etapa (Left Join)**:
- MantÃ©m **todas as linhas** do arquivo consolidado (sem multiplicaÃ§Ã£o)
- Adiciona apenas colunas necessÃ¡rias: RegistroANS, Modalidade, UF
- Registros sem match recebem "Registro sem match no cadastro"

**Por que nÃ£o um Ãºnico join?**
- Primeiro join Ã© por REG_ANS (chave primÃ¡ria em despesas)
- Segundo join Ã© por CNPJ (chave Ãºnica apÃ³s consolidaÃ§Ã£o)
- SeparaÃ§Ã£o mantÃ©m integridade referencial e evita duplicatas

**ImplementaÃ§Ã£o**:
```python
# Etapa 1: Despesas â†’ Operadoras (inner join por REG_ANS)
df_merged = df_despesas.merge(
    df_operadoras[[coluna_reg_ans_operadoras, coluna_cnpj, coluna_razao]],
    left_on=coluna_reg_ans_despesas,
    right_on=coluna_reg_ans_operadoras,
    how='inner'
)

# Etapa 2: Consolidado â†’ Operadoras (left join por CNPJ)
df_resultado = df_dados.merge(
    df_operadoras_filtradas,
    on='CNPJ',
    how='left'
)
```

**ValidaÃ§Ã£o**:
```python
# VerificaÃ§Ã£o simples para detectar efeitos colaterais inesperados durante o join
if num_linhas_resultado != num_linhas_original:
    raise ValueError(f"Join produziu {num_linhas_resultado} linhas em vez de {num_linhas_original}")
```

### 5. ConsolidaÃ§Ã£o e AgregaÃ§Ã£o

**Problema**: Empresas podem ter mÃºltiplas despesas no mesmo trimestre (diferentes tipos de despesa).

**DecisÃ£o**: **Agregar por (CNPJ, RazaoSocial, Trimestre, Ano)** usando `.groupby().agg()`.

**Justificativa**:
- AnÃ¡lise temporal requer **uma linha por empresa por trimestre**
- Soma de despesas mantÃ©m total correto
- AgregaÃ§Ã£o no final (apÃ³s validaÃ§Ã£o) garante dados limpos

**ImplementaÃ§Ã£o**:
```python
df_consolidado = df_consolidado.groupby(
    ['CNPJ', 'RazaoSocial', 'Trimestre', 'Ano'], 
    as_index=False
).agg({
    'ValorDespesas': 'sum'
})
```

### 6. OtimizaÃ§Ãµes de Performance

#### 6.1 SubstituiÃ§Ã£o de iterrows() por to_dict('records')

**Problema**: iterrows() tem overhead elevado em DataFrames grandes.

**DecisÃ£o**: Optei por uma abordagem vetorizada com .to_dict('records'), mais adequada ao volume de dados esperado.

**ImplementaÃ§Ã£o**:
```python
# ANTES (lento)
for _, row in df_merged.iterrows():
    resultados.append({...})

# DEPOIS (rÃ¡pido)
df_resultado = df_merged[['col1', 'col2', ...]].copy()
df_resultado.columns = ['new1', 'new2', ...]
resultados = df_resultado.to_dict('records')
```

#### 6.2 Download de Operadoras Uma Ãšnica Vez

**Problema**: Baixar o mesmo arquivo de operadoras para cada trimestre Ã© desperdÃ­cio.

**DecisÃ£o**: **Baixar UMA VEZ** antes do loop de trimestres.

**Justificativa**:
- Cadastro de operadoras nÃ£o muda entre trimestres
- Reduz trÃ¡fego de rede e tempo de execuÃ§Ã£o
- MemÃ³ria usada: ~50MB (aceitÃ¡vel para 3 trimestres)

**ImplementaÃ§Ã£o**:
```python
# Baixar operadoras UMA VEZ antes do loop
df_operadoras = pd.read_csv(caminho_operadoras, encoding='latin1', sep=';')

# Reusar em todos os trimestres
for arquivo in arquivos_trimestres:
    resultados = extrair_e_processar_zip(url_arquivo, df_operadoras)
```

### 7. PadrÃµes Brasileiros

**DecisÃ£o**: Usar **separador `;` e decimal `,`** em todos os CSVs.

**Justificativa**:
- PadrÃ£o brasileiro de CSV
- Compatibilidade com Excel em portuguÃªs
- Facilita abertura direta por usuÃ¡rios finais
- Encoding `utf-8-sig` para BOM (abre corretamente no Excel)

**ImplementaÃ§Ã£o**:
```python
df.to_csv(
    caminho_saida, 
    index=False, 
    encoding='utf-8-sig',  # BOM para Excel
    sep=';',               # Separador brasileiro
    decimal=','            # Decimal brasileiro
)
```

## ğŸ”§ Tecnologias Utilizadas

- **Python 3.x**
- **Pandas**: ManipulaÃ§Ã£o e anÃ¡lise de dados
- **Requests**: Download de arquivos HTTP
- **BeautifulSoup4**: Parsing de HTML (listagem de diretÃ³rios)
- **zipfile**: ExtraÃ§Ã£o de arquivos compactados
- **tempfile**: Gerenciamento de arquivos temporÃ¡rios

## ğŸ“¦ DependÃªncias

```bash
pip install pandas requests beautifulsoup4 openpyxl
```

## ğŸ“ LiÃ§Ãµes Aprendidas

1. **Sempre validar dados externos**: CNPJs invÃ¡lidos e duplicatas sÃ£o comuns em bases pÃºblicas
2. **Busca dinÃ¢mica de colunas**: Hardcoded names quebram quando a fonte muda
3. **AgregaÃ§Ã£o Ã© essencial**: Dados brutos raramente estÃ£o no formato ideal para anÃ¡lise
4. **Performance importa**: `iterrows()` vs `.to_dict()` pode ser diferenÃ§a de minutos vs segundos
5. **Processamento incremental**: Reduz pico de memÃ³ria sem sacrificar performance
6. **SeparaÃ§Ã£o de responsabilidades**: `main.py` (orquestraÃ§Ã£o) vs `processamento_dados.py` (lÃ³gica)

## ğŸ› Tratamento de Erros

O sistema implementa mÃºltiplas camadas de validaÃ§Ã£o:

- âœ… VerificaÃ§Ã£o de status HTTP (200) antes de processar
- âœ… Try-except em todas as funÃ§Ãµes crÃ­ticas (foi praticamente uma forma de debugar)
- âœ… ValidaÃ§Ã£o de existÃªncia de colunas antes de usar
- âœ… VerificaÃ§Ã£o de integridade apÃ³s joins
- âœ… Mensagens de debug detalhadas em cada etapa

## ğŸ“ˆ PrÃ³ximos Passos

- [ ] Adicionar testes unitÃ¡rios (pytest)
- [ ] Implementar logging estruturado (logging module)
- [ ] Criar CLI com argumentos (argparse)

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido para fins educacionais e de anÃ¡lise de dados pÃºblicos.

## ğŸ‘¤ Autor

**moonpie**  
Projeto: contabil-cli  
Data: Janeiro 2026

---

**Dados fornecidos por**: [ANS - AgÃªncia Nacional de SaÃºde Suplementar](https://dadosabertos.ans.gov.br/)